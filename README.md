# TSCP2_pytorch
Time Series Change Point Detection based on Contrastive Predictive Coding pytorch implementation



# Attention Layer Implementation
|Name|Citation|  
|---|---|  
|Additive Attention|[Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf)|  
|Dot-Product Attention|[Luong et al., 2015](https://arxiv.org/pdf/1508.04025.pdf)|  
|Location-Aware (Location Sensitive) Attention|[Chorowski et al., 2015](http://papers.nips.cc/paper/5847-attention-based-models-for-speech-recognition.pdf)|    
|Scaled Dot-Product Attention|[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)|  
|Multi-Head Attention|[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)|
|Relative Multi-Head Self Attention|[ZihangDai et al., 2019](https://arxiv.org/abs/1901.02860)|  

# Reference Repository
* https://github.com/sooftware/attentions
* 

# Reference Papers
* 